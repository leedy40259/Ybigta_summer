{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "0728_MLP.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leedy40259/Ybigta_summer/blob/main/0728_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN_pVd5cU2QQ"
      },
      "source": [
        "# 과제: MNIST 데이터를 나만의 NN model로 95 % 이상의 성능으로 training 시켜보자!\n",
        "\n",
        "\n",
        "## Loading MNIST training data\n",
        "\n",
        "출처: 19기 DS 정은서님"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwZNV5MFU2QQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a502acf-d85f-41cb-a24f-589d1428cbc8"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Loading the data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scaling(image data는 min-max scaling 주로 사용)\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDU8J2xRU2QQ"
      },
      "source": [
        "## Training Data\n",
        "28 * 28 pixel 값을 가진 총 60000개의 이미지 데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVvXmjQSU2QQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "360bb688-bbce-4a81-d170-f4b7ca9c6ce1"
      },
      "source": [
        "x_train.shape "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "x_train = x_train.astype('float64')\n",
        "x_test = x_test.astype('float64')\n",
        "# 각 element가 RGB 값이었는데 255로 나누어서 0과 1 사이의 값을 가지는 것 같음\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "# 이렇게 해야 logits and labels must have the same shape, received ((16, 10) vs (16, 1) 에러가 안뜸\n",
        "# 결과값 one-hot coding"
      ],
      "metadata": {
        "id": "rGe9FOHtJIrZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VTAAYKSU2QQ"
      },
      "source": [
        "Neural network 모델에 맞게 이미지 데이터를 벡터 형태로 데이터를 reshape 합니다.  \n",
        "(Model을 만들 때 *keras.layers.Flatten(input_shape=(28, 28)) 이용해도 됨)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq36yUX8U2QR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ffcd5d7-5bbc-46c2-b7fd-28e650d5a93a"
      },
      "source": [
        "x_train, x_test = x_train.reshape((-1, 28*28)), x_test.reshape((-1, 28*28))\n",
        "x_train.shape, x_test.shape\n",
        "# MLP에서는 1차원으로 쭉 펴서 입력층에 넣기 때문"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrQLH9iXU2QR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "9cf4897c-ab6b-49fb-a341-7bc0bf4b34ef"
      },
      "source": [
        "# Hint: x_train[0].reshape()\n",
        "plt.imshow(x_train[0].reshape(28, 28)).set_cmap('Greys')\n",
        "# train set의 첫 번째(index 0) 데이터 확인해보기. 쭉 폈던 걸 다시 원래 이미지 형태로 reshape해야 함"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YZXzr-AU2QR"
      },
      "source": [
        "## Training Labels\n",
        "이미지 데이터가 나타내는 숫자값을 label로 가지고 있고, 0부터 9까지의 값을 나타냄  \n",
        "마찬가지로, 60000개의 label이 존재"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-JVvQcJU2QR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da3d6518-201c-4627-d32c-d6d9c4864750"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgAkJK6yU2QR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4237734a-67c9-4db5-8c0a-7325d42fabf7"
      },
      "source": [
        "# show MNIST label for above data\n",
        "y_train[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaI3Kv_GU2QR"
      },
      "source": [
        "## 나만의 모델을 tensorflow keras API 를 이용해 만들어 봅시다~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSshVnt2U2QS"
      },
      "source": [
        "* parameters for model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coUZ53nKU2QS"
      },
      "source": [
        "activation_list = [\"sigmoid\", \"relu\", \"softmax\", \"tanh\"]\n",
        "\n",
        "loss_list = [\"sparse_categorical_crossentropy\",\n",
        "             \"categorical_crossentropy\", \n",
        "             \"binary_crossentropy\"]\n",
        "\n",
        "optimizer_list = [\"sgd\", \"adam\", \"rmsprop\", \"adagrad\"]\n",
        "\n",
        "initializer_list = [tf.keras.initializers.RandomNormal(), \n",
        "                    tf.keras.initializers.RandomUniform(), \n",
        "                    tf.keras.initializers.he_normal(), \n",
        "                    tf.keras.initializers.he_uniform(), \n",
        "                    tf.keras.initializers.GlorotUniform(),\n",
        "                    tf.keras.initializers.GlorotNormal()]\n",
        "\n",
        "# dropout\n",
        "dropout_rate = 0.3\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(256, input_dim=784, activation = \"sigmoid\"),\n",
        "    tf.keras.layers.Dense(2, activation = \"sigmoid\"),\n",
        "    tf.keras.layers.Dropout(dropout_rate)\n",
        "])\n",
        "\n",
        "\n",
        "# regularizer\n",
        "regularizer = tf.keras.regularizers.l1(1e-3)\n",
        "regularizer = tf.keras.regularizers.l2(1e-3)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(256, input_dim=784, activation=\"sigmoid\",\n",
        "                          activity_regularizer=regularizer)\n",
        "])\n",
        "\n",
        "# weight initialization\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(256, input_dim=784, activation=\"sigmoid\",\n",
        "                          kernel_initializer=initializer_list[0])\n",
        "])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-6ZTz4AU2QS"
      },
      "source": [
        "#### My Own Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziVbGe6sU2QS"
      },
      "source": [
        "#### 자유롭게 Model을 만들고 compile 해봅시다 ####\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "# input layer\n",
        "model.add(Dense(256, input_dim = 784, kernel_initializer = initializer_list[4], activation = activation_list[1]))\n",
        "model.add(Dropout(dropout_rate))\n",
        "# hidden layer 1(hidden layer부터는 input_dim 따로 설정 안해도 됨)\n",
        "model.add(Dense(50, kernel_initializer  = initializer_list[5], activation = activation_list[1]))\n",
        "model.add(Dropout(dropout_rate))\n",
        "# hidden layer 2\n",
        "model.add(Dense(10, kernel_initializer  = initializer_list[5], activation = activation_list[1]))\n",
        "model.add(Dropout(dropout_rate))\n",
        "# hidden layer 3\n",
        "model.add(Dense(50, kernel_initializer  = initializer_list[5], activation = activation_list[1]))\n",
        "model.add(Dropout(dropout_rate))\n",
        "# hidden layer 4\n",
        "model.add(Dense(50, kernel_initializer  = initializer_list[5], activation = activation_list[1]))\n",
        "model.add(Dropout(dropout_rate))\n",
        "# output layer (activation function은 softmax function)\n",
        "number_of_class = 10\n",
        "model.add(Dense(number_of_class, activation = 'sigmoid'))\n",
        "\n",
        "# compile (loss function과 optimizer, metrics 정함)\n",
        "# metrics: funciton that is used to judge the performance of your model\n",
        "model.compile(loss = loss_list[2],\n",
        "              optimizer = optimizer_list[2],\n",
        "              metrics = [\"accuracy\"])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVhLJHJ9U2QT"
      },
      "source": [
        "내가 만든 모델을 확인해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GChgw-8sU2QT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca918782-9f79-4d93-9c6b-92971cd36584"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 256)               200960    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 50)                12850     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                510       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 50)                550       \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 50)                2550      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                510       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 217,930\n",
            "Trainable params: 217,930\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9zWRRHIU2QT"
      },
      "source": [
        "model을 자유롭게 train 해봅시다.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uygJ19gU2QT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44c08eb7-bdfb-4c44-fd74-ba86f5753c55"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size = 16, epochs = 50)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3750/3750 [==============================] - 17s 4ms/step - loss: 0.1690 - accuracy: 0.6503\n",
            "Epoch 2/50\n",
            "3750/3750 [==============================] - 13s 4ms/step - loss: 0.1095 - accuracy: 0.8205\n",
            "Epoch 3/50\n",
            "3750/3750 [==============================] - 13s 4ms/step - loss: 0.1000 - accuracy: 0.8426\n",
            "Epoch 4/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.0980 - accuracy: 0.8470\n",
            "Epoch 5/50\n",
            "3750/3750 [==============================] - 13s 4ms/step - loss: 0.0988 - accuracy: 0.8506\n",
            "Epoch 6/50\n",
            "3750/3750 [==============================] - 13s 4ms/step - loss: 0.0992 - accuracy: 0.8519\n",
            "Epoch 7/50\n",
            "3750/3750 [==============================] - 13s 4ms/step - loss: 0.1005 - accuracy: 0.8545\n",
            "Epoch 8/50\n",
            "3750/3750 [==============================] - 13s 4ms/step - loss: 0.1006 - accuracy: 0.8543\n",
            "Epoch 9/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1039 - accuracy: 0.8536\n",
            "Epoch 10/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1037 - accuracy: 0.8554\n",
            "Epoch 11/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1064 - accuracy: 0.8541\n",
            "Epoch 12/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1105 - accuracy: 0.8497\n",
            "Epoch 13/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1121 - accuracy: 0.8494\n",
            "Epoch 14/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1132 - accuracy: 0.8463\n",
            "Epoch 15/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1171 - accuracy: 0.8457\n",
            "Epoch 16/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1194 - accuracy: 0.8456\n",
            "Epoch 17/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1211 - accuracy: 0.8442\n",
            "Epoch 18/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1250 - accuracy: 0.8366\n",
            "Epoch 19/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1264 - accuracy: 0.8366\n",
            "Epoch 20/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1272 - accuracy: 0.8339\n",
            "Epoch 21/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1309 - accuracy: 0.8334\n",
            "Epoch 22/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1336 - accuracy: 0.8317\n",
            "Epoch 23/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1387 - accuracy: 0.8226\n",
            "Epoch 24/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1371 - accuracy: 0.8236\n",
            "Epoch 25/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1395 - accuracy: 0.8172\n",
            "Epoch 26/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1472 - accuracy: 0.8132\n",
            "Epoch 27/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1460 - accuracy: 0.8124\n",
            "Epoch 28/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1473 - accuracy: 0.8090\n",
            "Epoch 29/50\n",
            "3750/3750 [==============================] - 15s 4ms/step - loss: 0.1485 - accuracy: 0.8051\n",
            "Epoch 30/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1551 - accuracy: 0.8052\n",
            "Epoch 31/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1514 - accuracy: 0.8045\n",
            "Epoch 32/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1569 - accuracy: 0.8010\n",
            "Epoch 33/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1622 - accuracy: 0.8026\n",
            "Epoch 34/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1701 - accuracy: 0.7975\n",
            "Epoch 35/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1633 - accuracy: 0.7959\n",
            "Epoch 36/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1660 - accuracy: 0.7962\n",
            "Epoch 37/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1686 - accuracy: 0.7943\n",
            "Epoch 38/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1825 - accuracy: 0.7876\n",
            "Epoch 39/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1742 - accuracy: 0.7912\n",
            "Epoch 40/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1744 - accuracy: 0.7935\n",
            "Epoch 41/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1790 - accuracy: 0.7834\n",
            "Epoch 42/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1774 - accuracy: 0.7794\n",
            "Epoch 43/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1864 - accuracy: 0.7801\n",
            "Epoch 44/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1850 - accuracy: 0.7782\n",
            "Epoch 45/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1870 - accuracy: 0.7812\n",
            "Epoch 46/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.2060 - accuracy: 0.7757\n",
            "Epoch 47/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1957 - accuracy: 0.7717\n",
            "Epoch 48/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1928 - accuracy: 0.7669\n",
            "Epoch 49/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.1998 - accuracy: 0.7610\n",
            "Epoch 50/50\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.2007 - accuracy: 0.7548\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc51bbb90d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8A4zKnEU2QT"
      },
      "source": [
        "95%이상의 성능을 가진 모델을 만들면 완성!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xz0qGifU2QU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4db44f62-fad0-4b3d-dab7-9926a4b1345f"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(x_test,y_test, verbose=2)\n",
        "\n",
        "print('\\nAccuracy:', test_acc)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - loss: 0.0579 - accuracy: 0.9436 - 839ms/epoch - 3ms/step\n",
            "\n",
            "Accuracy: 0.9435999989509583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "EbcuzK_PU2QU"
      },
      "source": [
        "![](https://www.tensorflow.org/versions/master/images/mnist_tensorboard.png)"
      ]
    }
  ]
}